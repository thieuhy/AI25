{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/thieuhy/AgenticAI_Business_SJSU/blob/Agentic-AI-in-Marketing/Group_8_Agentic_AI_in_Marketing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# README\n",
        "\n",
        "**How to Run:**  \n",
        "1. Open and run all notebook cells from top to bottom.  \n",
        "2. The agent will:\n",
        "   - Read campaign data from `marketing_campaign_dataset.xlsx`\n",
        "   - Compute per-channel performance (CTR, CVR, CPA)\n",
        "   - Allocate daily budgets using a heuristic + guardrails\n",
        "   - Save outputs to:\n",
        "     - `agent_decisions_log.csv` — daily decisions and rationales  \n",
        "     - `agent_allocations.csv` — budget allocations  \n",
        "     - `summary_comparison.csv` — baseline vs. optimized results  \n",
        "\n",
        "**Assumptions:**  \n",
        "- 3–4 channels (e.g., Search, Social, Display)  \n",
        "- ~14–30 days of data from the Excel file  \n",
        "- Optimization aims to improve conversions with fairness (±20% cap, 10% floor)  \n",
        "- No use of personal or sensitive data  \n",
        "\n",
        "**Results Snapshot (Example):**\n",
        "\n",
        "| Metric | Baseline | Optimized | Δ (%) |\n",
        "|--------|-----------|------------|-------|\n",
        "| Total Conversions | 118 | 131 | +11.0% |\n",
        "| Avg CPA | 13.2 | 12.1 | -8.3% |\n",
        "| CTR | 2.4% | 2.6% | +8.5% |\n",
        "\n",
        "\n",
        "**Observation:**  \n",
        "The heuristic agent increased conversions while maintaining exploration and respecting daily guardrails."
      ],
      "metadata": {
        "id": "bPmv0_E5DMdw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hsnn-0sKaSkR",
        "outputId": "827c8f74-0ad3-4f49-8000-772da68d7e29"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/76.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━\u001b[0m \u001b[32m71.7/76.0 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.0/76.0 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hEnter your OpenAI API key: ··········\n",
            "✅ LangChain + OpenAI setup complete.\n"
          ]
        }
      ],
      "source": [
        "# --- install dependencies (run once per session)\n",
        "!pip -q install langchain langchain_openai openai\n",
        "\n",
        "# --- imports\n",
        "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
        "import os\n",
        "from getpass import getpass\n",
        "\n",
        "# --- ask each user to enter their own key securely\n",
        "if not os.getenv(\"OPENAI_API_KEY\"):\n",
        "    os.environ[\"OPENAI_API_KEY\"] = getpass(\"Enter your OpenAI API key: \")\n",
        "\n",
        "# --- setup the model + embeddings\n",
        "model = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.3)\n",
        "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
        "\n",
        "print(\"✅ LangChain + OpenAI setup complete.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rm_gPFKORiuQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a7970df4-9076-4975-c8e3-82e667cca747"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Summary (Totals) ===\n",
            "        Baseline_Equal                                                      \\\n",
            "                 spend   impressions      clicks conversions    CTR    CVR   \n",
            "channel                                                                      \n",
            "Search         21000.0  2.565404e+06  116151.630    5190.898  0.045  0.045   \n",
            "Social         21000.0  4.179256e+06   49181.759    1201.434  0.012  0.024   \n",
            "Display        21000.0  6.070259e+06   36219.425     413.697  0.006  0.011   \n",
            "TOTAL          63000.0  1.281492e+07  201552.814    6806.029  0.016  0.034   \n",
            "\n",
            "                     Agent                                                     \\\n",
            "            CPA      spend  impressions      clicks conversions    CTR    CVR   \n",
            "channel                                                                         \n",
            "Search    4.046  44747.465  5463437.021  245784.885   11029.516  0.045  0.045   \n",
            "Social   17.479   9126.267  1815350.565   21549.472     523.602  0.012  0.024   \n",
            "Display  50.762   9126.267  2621987.858   15541.827     175.699  0.006  0.011   \n",
            "TOTAL     9.256  63000.000  9900775.444  282876.185   11728.817  0.029  0.041   \n",
            "\n",
            "                 \n",
            "            CPA  \n",
            "channel          \n",
            "Search    4.057  \n",
            "Social   17.430  \n",
            "Display  51.943  \n",
            "TOTAL     5.371  \n",
            "\n",
            "=== Sample Decisions ===\n",
            "         date          decision  \\\n",
            "0  2025-10-15  Init equal split   \n",
            "1  2025-10-16      Boost Search   \n",
            "2  2025-10-17      Boost Search   \n",
            "3  2025-10-18      Boost Search   \n",
            "4  2025-10-19      Boost Search   \n",
            "5  2025-10-20      Boost Search   \n",
            "6  2025-10-21      Boost Search   \n",
            "7  2025-10-22      Boost Search   \n",
            "\n",
            "                                              reason  \n",
            "0  Start exploration with equal allocation across...  \n",
            "1  Search up by ~15% due to higher CVR-pref (CTR ...  \n",
            "2  Search up by ~15% due to higher CVR-pref (CTR ...  \n",
            "3  Search up by ~15% due to higher CVR-pref (CTR ...  \n",
            "4  Search up by ~15% due to higher CVR-pref (CTR ...  \n",
            "5  Search up by ~15% due to higher CVR-pref (CTR ...  \n",
            "6  Search up by ~15% due to higher CVR-pref (CTR ...  \n",
            "7  Search up by ~15% due to higher CVR-pref (CTR ...  \n",
            "\n",
            "Artifacts saved to: ./ad_agent_outputs\n"
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "Ad Optimization Agent (3 channels): equal-start + explore/exploit + guardrails\n",
        "- Baseline: equal split daily\n",
        "- Agent: shift +10–20% toward prior-day top performer by CVR (CTR fallback)\n",
        "- Guardrails: per-day change cap (±20%), min floor for all channels, never allocate 0% > 2 days\n",
        "- Evaluation: total conversions, total clicks, CPA vs baseline\n",
        "\"\"\"\n",
        "\n",
        "\"\"\"\n",
        "Guardrails:\n",
        "- Limit budget changes to ±20% per day (prevents big swings)\n",
        "- Maintain a minimum 15% spend per channel (keeps learning active)\n",
        "- No channel can stay near 0% for more than 2 days (avoids abandonment)\n",
        "- Always re-normalize allocations to sum to 100%\n",
        "- Use CVR to choose top performer (CTR fallback if clicks are low)\n",
        "\"\"\"\n",
        "\n",
        "import os\n",
        "from dataclasses import dataclass\n",
        "import math\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from datetime import datetime, timedelta\n",
        "np.random.seed(7)\n",
        "\n",
        "# =========================\n",
        "# CONFIG\n",
        "# =========================\n",
        "CHANNELS = [\"Search\", \"Social\", \"Display\"]\n",
        "DAYS = 21\n",
        "DAILY_BUDGET = 3000.0\n",
        "\n",
        "# Heuristic knobs\n",
        "SHIFT_PCT = 0.15             # shift 10–20% toward top (set 0.10–0.20)\n",
        "MIN_FLOOR_PCT = 0.15         # never allocate below 15% (keeps learning alive)\n",
        "MAX_DELTA_PCT = 0.20         # per-day change cap (+/-20%)\n",
        "ZERO_MAX_STREAK = 2          # never 0% for > 2 consecutive days\n",
        "\n",
        "# Eval metric priority (CVR with CTR fallback)\n",
        "PRIORITY_METRIC = \"CVR\"      # computed as conversions / clicks (fallback CTR if clicks==0)\n",
        "\n",
        "OUTDIR = \"./ad_agent_outputs\"\n",
        "os.makedirs(OUTDIR, exist_ok=True)\n",
        "\n",
        "# =========================\n",
        "# UTILITIES\n",
        "# =========================\n",
        "@dataclass\n",
        "class DayOutcome:\n",
        "    date: str\n",
        "    channel: str\n",
        "    spend: float\n",
        "    impressions: float\n",
        "    clicks: float\n",
        "    conversions: float\n",
        "\n",
        "def summarize(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    g = df.groupby(\"channel\").agg(\n",
        "        spend=(\"spend\", \"sum\"),\n",
        "        impressions=(\"impressions\", \"sum\"),\n",
        "        clicks=(\"clicks\", \"sum\"),\n",
        "        conversions=(\"conversions\", \"sum\"),\n",
        "    )\n",
        "    g.loc[\"TOTAL\"] = g.sum(numeric_only=True)\n",
        "    g[\"CTR\"] = g[\"clicks\"] / g[\"impressions\"]\n",
        "    g[\"CVR\"] = g[\"conversions\"] / g[\"clicks\"]\n",
        "    g[\"CPA\"] = g[\"spend\"] / g[\"conversions\"]\n",
        "    return g\n",
        "\n",
        "def safe_div(num, den):\n",
        "    return num / den if den > 0 else 0.0\n",
        "\n",
        "# =========================\n",
        "# DATA INPUT\n",
        "# =========================\n",
        "\"\"\"\n",
        "Option A (default): create a simple synthetic dataset with latent rates.\n",
        "Option B: read your own CSV/Excel with columns: date,channel,impressions,clicks,conversions.\n",
        "   - To use Option B, set USE_EXTERNAL=True and provide a path (CSV or XLSX).\n",
        "\"\"\"\n",
        "USE_EXTERNAL = False\n",
        "EXTERNAL_PATH = \"./marketing_campaign_dataset.xlsx\"  # or .csv\n",
        "\n",
        "def build_dates(n_days: int):\n",
        "    start = datetime.today().date() - timedelta(days=n_days)\n",
        "    return [start + timedelta(days=i) for i in range(n_days)]\n",
        "\n",
        "def make_synthetic_latent():\n",
        "    \"\"\"Latent CTR/CVR/CPM per channel, slightly noisy by day.\"\"\"\n",
        "    profiles = {\n",
        "        \"Search\":  {\"ctr\": 0.045, \"cvr\": 0.045, \"cpm\": 8.0},\n",
        "        \"Social\":  {\"ctr\": 0.012, \"cvr\": 0.025, \"cpm\": 5.0},\n",
        "        \"Display\": {\"ctr\": 0.006, \"cvr\": 0.012, \"cpm\": 3.5},\n",
        "    }\n",
        "    dates = build_dates(DAYS)\n",
        "    rows = []\n",
        "    for d in dates:\n",
        "        for ch in CHANNELS:\n",
        "            ctr = max(0.0001, np.random.normal(profiles[ch][\"ctr\"], profiles[ch][\"ctr\"]*0.12))\n",
        "            cvr = max(0.0001, np.random.normal(profiles[ch][\"cvr\"], profiles[ch][\"cvr\"]*0.12))\n",
        "            cpm = max(1.0, np.random.normal(profiles[ch][\"cpm\"], profiles[ch][\"cpm\"]*0.08))\n",
        "            rows.append({\"date\": d.isoformat(), \"channel\": ch, \"ctr\": ctr, \"cvr\": cvr, \"cpm\": cpm})\n",
        "    return pd.DataFrame(rows)\n",
        "\n",
        "def simulate_day(latent_df: pd.DataFrame, date_str: str, alloc_pct: dict) -> pd.DataFrame:\n",
        "    \"\"\"Use CPM to convert budget to impressions, then CTR->clicks, CVR->conversions.\"\"\"\n",
        "    day_params = latent_df[latent_df[\"date\"] == date_str]\n",
        "    out = []\n",
        "    for ch in CHANNELS:\n",
        "        spend = DAILY_BUDGET * alloc_pct[ch]\n",
        "        cpm = float(day_params.loc[day_params[\"channel\"] == ch, \"cpm\"].iloc[0])\n",
        "        ctr = float(day_params.loc[day_params[\"channel\"] == ch, \"ctr\"].iloc[0])\n",
        "        cvr = float(day_params.loc[day_params[\"channel\"] == ch, \"cvr\"].iloc[0])\n",
        "        imps = (spend / cpm) * 1000.0\n",
        "        clicks = imps * ctr\n",
        "        conv = clicks * cvr\n",
        "        out.append(DayOutcome(date_str, ch, spend, imps, clicks, conv).__dict__)\n",
        "    return pd.DataFrame(out)\n",
        "\n",
        "def load_external_perf(path: str) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Expect columns: date,channel,impressions,clicks,conversions\n",
        "    We will estimate CPM per channel-day to translate budget to impressions realistically.\n",
        "    \"\"\"\n",
        "    if path.endswith(\".xlsx\"):\n",
        "        raw = pd.read_excel(path)\n",
        "    else:\n",
        "        raw = pd.read_csv(path)\n",
        "    # clean and conform\n",
        "    need = {\"date\",\"channel\",\"impressions\",\"clicks\",\"conversions\"}\n",
        "    assert need.issubset(set(raw.columns)), f\"Missing required columns: {need - set(raw.columns)}\"\n",
        "    df = raw.copy()\n",
        "    # Keep last DAYS * 3 rows if too large (or aggregate by date/channel)\n",
        "    df[\"date\"] = pd.to_datetime(df[\"date\"]).dt.date.astype(str)\n",
        "    # Ensure exactly DAYS per channel; if not, sample or pad\n",
        "    # For simplicity, just take most recent DAYS per channel if more available\n",
        "    perf = []\n",
        "    for ch in CHANNELS:\n",
        "        sub = df[df[\"channel\"].str.lower() == ch.lower()].copy()\n",
        "        if sub.empty:\n",
        "            raise ValueError(f\"No rows found for channel {ch} in external file.\")\n",
        "        sub = sub.sort_values(\"date\").tail(DAYS)\n",
        "        # Estimate CTR/CVR to use as day parameters; derive CPM by an assumed $5 baseline scaled by density\n",
        "        sub[\"ctr\"] = sub[\"clicks\"] / sub[\"impressions\"].replace(0, np.nan)\n",
        "        sub[\"ctr\"] = sub[\"ctr\"].fillna(0.001).clip(lower=0.0001)\n",
        "        sub[\"cvr\"] = sub[\"conversions\"] / sub[\"clicks\"].replace(0, np.nan)\n",
        "        sub[\"cvr\"] = sub[\"cvr\"].fillna(0.01).clip(lower=0.0001)\n",
        "        # crude CPM proxy: lower impressions per unit click ⇒ higher CPM; bound to [3,12]\n",
        "        density = (sub[\"impressions\"] / (sub[\"clicks\"].replace(0,np.nan))).fillna(1000)\n",
        "        sub[\"cpm\"] = (density / density.median()) * 6\n",
        "        sub[\"cpm\"] = sub[\"cpm\"].clip(3, 12)\n",
        "        sub[\"channel\"] = ch\n",
        "        perf.append(sub[[\"date\",\"channel\",\"ctr\",\"cvr\",\"cpm\"]])\n",
        "    return pd.concat(perf, ignore_index=True)\n",
        "\n",
        "if USE_EXTERNAL:\n",
        "    latent = load_external_perf(EXTERNAL_PATH)\n",
        "else:\n",
        "    latent = make_synthetic_latent()\n",
        "\n",
        "latent.to_csv(os.path.join(OUTDIR, \"latent_params.csv\"), index=False)\n",
        "\n",
        "DATES = sorted(latent[\"date\"].unique().tolist())\n",
        "assert len(DATES) == DAYS, \"Unexpected number of days in latent frame.\"\n",
        "\n",
        "# =========================\n",
        "# BASELINE: equal split every day\n",
        "# =========================\n",
        "equal_alloc = {ch: 1.0/len(CHANNELS) for ch in CHANNELS}\n",
        "baseline_runs = []\n",
        "for d in DATES:\n",
        "    baseline_runs.append(simulate_day(latent, d, equal_alloc))\n",
        "baseline_df = pd.concat(baseline_runs, ignore_index=True)\n",
        "baseline_df.to_csv(os.path.join(OUTDIR, \"baseline_equal.csv\"), index=False)\n",
        "\n",
        "# =========================\n",
        "# AGENT: explore/exploit with guardrails\n",
        "# =========================\n",
        "def compute_scores(df_prev_day: pd.DataFrame) -> dict:\n",
        "    g = df_prev_day.groupby(\"channel\").sum(numeric_only=True)\n",
        "    scores = {}\n",
        "    for ch in CHANNELS:\n",
        "        clicks = float(g.loc[ch, \"clicks\"]) if ch in g.index else 0.0\n",
        "        convs = float(g.loc[ch, \"conversions\"]) if ch in g.index else 0.0\n",
        "        imps  = float(g.loc[ch, \"impressions\"]) if ch in g.index else 0.0\n",
        "        if clicks > 0:\n",
        "            cvr = convs / clicks\n",
        "            scores[ch] = cvr\n",
        "        else:\n",
        "            ctr = clicks / imps if imps > 0 else 0.0\n",
        "            scores[ch] = ctr\n",
        "    return scores  # higher is better\n",
        "\n",
        "def apply_guardrails(prev_alloc: dict, proposed: dict, zero_streaks: dict) -> dict:\n",
        "    guarded = {}\n",
        "    # 1) per-day delta cap and min floor\n",
        "    for ch in CHANNELS:\n",
        "        prev = prev_alloc[ch]\n",
        "        prop = proposed[ch]\n",
        "        delta = np.clip(prop - prev, -MAX_DELTA_PCT, MAX_DELTA_PCT)\n",
        "        prop = prev + delta\n",
        "        prop = max(prop, MIN_FLOOR_PCT)   # exploration floor\n",
        "        guarded[ch] = prop\n",
        "    # 2) never 0% for >2 days — bump channel if streak exceeded\n",
        "    for ch in CHANNELS:\n",
        "        if zero_streaks[ch] > ZERO_MAX_STREAK and guarded[ch] <= 0.001:\n",
        "            guarded[ch] = max(guarded[ch], MIN_FLOOR_PCT)\n",
        "    # 3) renormalize to 1.0\n",
        "    s = sum(guarded.values())\n",
        "    for ch in CHANNELS:\n",
        "        guarded[ch] = guarded[ch] / s\n",
        "    return guarded\n",
        "\n",
        "# State\n",
        "agent_alloc = equal_alloc.copy()\n",
        "agent_logs = []\n",
        "alloc_history = []\n",
        "decision_log = []  # rationale strings\n",
        "zero_streaks = {ch: 0 for ch in CHANNELS}\n",
        "\n",
        "# Day 0\n",
        "d0 = DATES[0]\n",
        "day0 = simulate_day(latent, d0, agent_alloc)\n",
        "agent_logs.append(day0)\n",
        "alloc_history.append({\"date\": d0, **agent_alloc})\n",
        "decision_log.append({\n",
        "    \"date\": d0,\n",
        "    \"decision\": \"Init equal split\",\n",
        "    \"reason\": \"Start exploration with equal allocation across channels.\"\n",
        "})\n",
        "\n",
        "# Subsequent days\n",
        "for i in range(1, len(DATES)):\n",
        "    prev_day = agent_logs[-1]\n",
        "    scores = compute_scores(prev_day)\n",
        "    top = max(scores, key=scores.get)\n",
        "\n",
        "    # Propose: shift SHIFT_PCT toward top, take evenly from others\n",
        "    proposed = agent_alloc.copy()\n",
        "    add = SHIFT_PCT\n",
        "    others = [c for c in CHANNELS if c != top]\n",
        "    for o in others:\n",
        "        proposed[o] -= add / len(others)\n",
        "    proposed[top] += add\n",
        "\n",
        "    # Guardrails\n",
        "    guarded = apply_guardrails(agent_alloc, proposed, zero_streaks)\n",
        "\n",
        "    # Log zero streaks (if any channel effectively zero)\n",
        "    for ch in CHANNELS:\n",
        "        if guarded[ch] <= 0.001:\n",
        "            zero_streaks[ch] += 1\n",
        "        else:\n",
        "            zero_streaks[ch] = 0\n",
        "\n",
        "    # Human-readable rationale\n",
        "    metric_used = \"CVR-pref (CTR fallback)\"\n",
        "    reason = (\n",
        "        f\"{top} up by ~{int(add*100)}% due to higher {metric_used} on {DATES[i-1]}. \"\n",
        "        f\"Applied guardrails: ±{int(MAX_DELTA_PCT*100)}% cap, \"\n",
        "        f\"min floor {int(MIN_FLOOR_PCT*100)}%, zero-streak≤{ZERO_MAX_STREAK}.\"\n",
        "    )\n",
        "\n",
        "    # Apply and simulate\n",
        "    agent_alloc = guarded\n",
        "    di = DATES[i]\n",
        "    out = simulate_day(latent, di, agent_alloc)\n",
        "    agent_logs.append(out)\n",
        "    alloc_history.append({\"date\": di, **agent_alloc})\n",
        "    decision_log.append({\"date\": di, \"decision\": f\"Boost {top}\", \"reason\": reason})\n",
        "\n",
        "agent_df = pd.concat(agent_logs, ignore_index=True)\n",
        "alloc_hist_df = pd.DataFrame(alloc_history)\n",
        "decisions_df = pd.DataFrame(decision_log)\n",
        "\n",
        "# =========================\n",
        "# EVALUATION\n",
        "# =========================\n",
        "sum_base = summarize(baseline_df)\n",
        "sum_agent = summarize(agent_df)\n",
        "\n",
        "comparison = pd.concat(\n",
        "    {\"Baseline_Equal\": sum_base.loc[[\"Search\",\"Social\",\"Display\",\"TOTAL\"]],\n",
        "     \"Agent\": sum_agent.loc[[\"Search\",\"Social\",\"Display\",\"TOTAL\"]]},\n",
        "    axis=1\n",
        ")\n",
        "\n",
        "# Save artifacts\n",
        "baseline_df.to_csv(os.path.join(OUTDIR, \"baseline_outcomes.csv\"), index=False)\n",
        "agent_df.to_csv(os.path.join(OUTDIR, \"agent_outcomes.csv\"), index=False)\n",
        "alloc_hist_df.to_csv(os.path.join(OUTDIR, \"agent_allocations.csv\"), index=False)\n",
        "decisions_df.to_csv(os.path.join(OUTDIR, \"agent_decisions_log.csv\"), index=False)\n",
        "comparison.to_csv(os.path.join(OUTDIR, \"summary_comparison.csv\"))\n",
        "\n",
        "# Print snapshots\n",
        "print(\"=== Summary (Totals) ===\")\n",
        "print(comparison.round(3))\n",
        "print(\"\\n=== Sample Decisions ===\")\n",
        "print(decisions_df.head(8))\n",
        "print(f\"\\nArtifacts saved to: {OUTDIR}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jp08DRAguL9V",
        "outputId": "674f2b1f-aa12-48eb-a0cc-0e1631f0204f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: langgraph in /usr/local/lib/python3.12/dist-packages (1.0.2)\n",
            "Requirement already satisfied: langchain in /usr/local/lib/python3.12/dist-packages (1.0.3)\n",
            "Requirement already satisfied: langchain_openai in /usr/local/lib/python3.12/dist-packages (1.0.2)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.12/dist-packages (2.11.10)\n",
            "Requirement already satisfied: langchain-core>=0.1 in /usr/local/lib/python3.12/dist-packages (from langgraph) (1.0.3)\n",
            "Requirement already satisfied: langgraph-checkpoint<4.0.0,>=2.1.0 in /usr/local/lib/python3.12/dist-packages (from langgraph) (3.0.0)\n",
            "Requirement already satisfied: langgraph-prebuilt<1.1.0,>=1.0.2 in /usr/local/lib/python3.12/dist-packages (from langgraph) (1.0.2)\n",
            "Requirement already satisfied: langgraph-sdk<0.3.0,>=0.2.2 in /usr/local/lib/python3.12/dist-packages (from langgraph) (0.2.9)\n",
            "Requirement already satisfied: xxhash>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from langgraph) (3.6.0)\n",
            "Requirement already satisfied: openai<3.0.0,>=1.109.1 in /usr/local/lib/python3.12/dist-packages (from langchain_openai) (1.109.1)\n",
            "Requirement already satisfied: tiktoken<1.0.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from langchain_openai) (0.12.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic) (2.33.2)\n",
            "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.12/dist-packages (from pydantic) (4.15.0)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic) (0.4.2)\n",
            "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core>=0.1->langgraph) (1.33)\n",
            "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in /usr/local/lib/python3.12/dist-packages (from langchain-core>=0.1->langgraph) (0.4.38)\n",
            "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core>=0.1->langgraph) (25.0)\n",
            "Requirement already satisfied: pyyaml<7.0.0,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core>=0.1->langgraph) (6.0.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core>=0.1->langgraph) (8.5.0)\n",
            "Requirement already satisfied: ormsgpack>=1.10.0 in /usr/local/lib/python3.12/dist-packages (from langgraph-checkpoint<4.0.0,>=2.1.0->langgraph) (1.11.0)\n",
            "Requirement already satisfied: httpx>=0.25.2 in /usr/local/lib/python3.12/dist-packages (from langgraph-sdk<0.3.0,>=0.2.2->langgraph) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.10.1 in /usr/local/lib/python3.12/dist-packages (from langgraph-sdk<0.3.0,>=0.2.2->langgraph) (3.11.4)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=1.109.1->langchain_openai) (4.11.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=1.109.1->langchain_openai) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=1.109.1->langchain_openai) (0.11.1)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=1.109.1->langchain_openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=1.109.1->langchain_openai) (4.67.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.12/dist-packages (from tiktoken<1.0.0,>=0.7.0->langchain_openai) (2024.11.6)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.12/dist-packages (from tiktoken<1.0.0,>=0.7.0->langchain_openai) (2.32.4)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.5.0->openai<3.0.0,>=1.109.1->langchain_openai) (3.11)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (2025.10.5)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core>=0.1->langgraph) (3.0.0)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core>=0.1->langgraph) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core>=0.1->langgraph) (0.25.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken<1.0.0,>=0.7.0->langchain_openai) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken<1.0.0,>=0.7.0->langchain_openai) (2.5.0)\n"
          ]
        }
      ],
      "source": [
        "pip install langgraph langchain langchain_openai pydantic"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZdXebpsDuMVl"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import operator\n",
        "from typing import TypedDict, Annotated, List\n",
        "\n",
        "from langchain_core.messages import BaseMessage, HumanMessage\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.tools import tool\n",
        "from langgraph.graph import StateGraph, END\n",
        "\n",
        "from google.colab import userdata\n",
        "\n",
        "# --- ask each user to enter their own key securely\n",
        "if not os.getenv(\"OPENAI_API_KEY\"):\n",
        "    os.environ[\"OPENAI_API_KEY\"] = getpass(\"Enter your OpenAI API key: \")\n",
        "\n",
        "# 1. Define the Agent State\n",
        "# This represents the information passed between nodes in the graph\n",
        "class AgentState(TypedDict):\n",
        "    \"\"\"\n",
        "    Represents the state of our ad optimization agent.\n",
        "    - messages: A list of messages/history.\n",
        "    - campaign_data: The current (simulated) ad campaign metrics.\n",
        "    - next_action: The recommended action from the analysis.\n",
        "    \"\"\"\n",
        "    messages: Annotated[List[BaseMessage], operator.add]\n",
        "    campaign_data: dict\n",
        "    next_action: str\n",
        "\n",
        "# 2. Initialize LLM\n",
        "# We'll use a powerful model for the reasoning engine\n",
        "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
        "\n",
        "print(\"✅ LangChain + OpenAI setup complete.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kn7XhZK8ucsp"
      },
      "outputs": [],
      "source": [
        "# --- Simulated Tools for Ad Optimization ---\n",
        "\n",
        "@tool\n",
        "def adjust_bid(campaign_id: str, new_bid_amount: float) -> str:\n",
        "    \"\"\"Adjusts the bid for a specific ad campaign to the new amount.\"\"\"\n",
        "    if new_bid_amount > 5.00:\n",
        "        return f\"Bid for Campaign '{campaign_id}' adjusted to ${new_bid_amount:.2f}. (Simulated: High bid warning!)\"\n",
        "    return f\"Bid for Campaign '{campaign_id}' adjusted to ${new_bid_amount:.2f} successfully.\"\n",
        "\n",
        "@tool\n",
        "def pause_ad_group(ad_group_id: str) -> str:\n",
        "    \"\"\"Pauses an underperforming ad group by its ID.\"\"\"\n",
        "    return f\"Ad Group '{ad_group_id}' paused successfully due to poor performance.\"\n",
        "\n",
        "@tool\n",
        "def request_new_creatives(campaign_id: str) -> str:\n",
        "    \"\"\"Requests new ad creative assets from the creative team.\"\"\"\n",
        "    return f\"New creative request submitted for Campaign '{campaign_id}'. Awaiting design feedback.\"\n",
        "\n",
        "ad_optimization_tools = [adjust_bid, pause_ad_group, request_new_creatives]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1pIBTnAVuf8V"
      },
      "outputs": [],
      "source": [
        "def fetch_campaign_data(state: AgentState) -> dict:\n",
        "    \"\"\"Simulates fetching the latest campaign data.\"\"\"\n",
        "    print(\"--- FETCHING DATA ---\")\n",
        "    # In a real scenario, this would call an Ad API (e.g., Google Ads, Meta)\n",
        "    # This is a fixed, simulated dataset for the workshop\n",
        "    simulated_data = {\n",
        "        \"Campaign-2024-Q4\": {\n",
        "            \"Budget\": 1000, \"Spend\": 850, \"Impressions\": 50000,\n",
        "            \"Clicks\": 500, \"Conversions\": 5, \"CPA\": 170.00, \"Target_CPA\": 50.00,\n",
        "            \"Ad_Groups\": {\n",
        "                \"AG-101\": {\"Status\": \"Active\", \"CPA\": 25.00, \"Bid\": 2.50},\n",
        "                \"AG-102\": {\"Status\": \"Active\", \"CPA\": 450.00, \"Bid\": 3.00} # Poor performer\n",
        "            }\n",
        "        }\n",
        "    }\n",
        "\n",
        "    analysis_prompt = (\n",
        "        \"Ad Campaign Data for Optimization:\\n\"\n",
        "        f\"{simulated_data}\\n\\n\"\n",
        "        \"**Optimization Goal:** Reduce overall CPA (Cost Per Acquisition) to be closer to the Target CPA ($50.00) \"\n",
        "        \"and maximize conversions. Analyze the data and recommend the *single best action* \"\n",
        "        \"using one of the provided tools (adjust_bid, pause_ad_group, request_new_creatives). \"\n",
        "        \"Your final output should be ONLY the recommended action as a message for the user, \"\n",
        "        \"or a clear instruction for the next internal step.\"\n",
        "    )\n",
        "\n",
        "    # Prepend the analysis prompt to the messages for the LLM\n",
        "    new_messages = [HumanMessage(content=analysis_prompt)]\n",
        "\n",
        "    return {\"messages\": new_messages, \"campaign_data\": simulated_data}\n",
        "\n",
        "def agent_reasoning(state: AgentState) -> dict:\n",
        "    \"\"\"The LLM reasons and decides the next step (tool call or final answer).\"\"\"\n",
        "    print(\"--- AGENT REASONING ---\")\n",
        "\n",
        "    # Bind the tools to the LLM\n",
        "    llm_with_tools = llm.bind_tools(ad_optimization_tools)\n",
        "\n",
        "    # Define a system prompt to guide the LLM's role\n",
        "    system_prompt = (\n",
        "        \"You are an expert Ad Campaign Optimization Agent. \"\n",
        "        \"Your goal is to analyze the provided campaign data and decide the optimal next action. \"\n",
        "        \"You must use a tool if an optimization is possible. \"\n",
        "        \"If no tool is needed or you have executed a tool, provide a final, concise update.\"\n",
        "    )\n",
        "\n",
        "    prompt = ChatPromptTemplate.from_messages([\n",
        "        (\"system\", system_prompt),\n",
        "        (\"placeholder\", \"{messages}\")\n",
        "    ])\n",
        "\n",
        "    # Run the LLM to get a decision\n",
        "    chain = prompt | llm_with_tools\n",
        "    response = chain.invoke(state)\n",
        "\n",
        "    # Determine if a tool call was made\n",
        "    if response.tool_calls:\n",
        "        # If a tool is called, the next step is to execute it.\n",
        "        return {\"messages\": [response], \"next_action\": \"call_tool\"}\n",
        "    else:\n",
        "        # If no tool is called, the reasoning is the final response.\n",
        "        return {\"messages\": [response], \"next_action\": \"FINISH\"}\n",
        "\n",
        "\n",
        "def execute_tools(state: AgentState) -> dict:\n",
        "    \"\"\"Executes the tool call(s) decided by the agent_reasoning step.\"\"\"\n",
        "    print(\"--- EXECUTING TOOL ---\")\n",
        "\n",
        "    tool_calls = state[\"messages\"][-1].tool_calls\n",
        "    tool_results = []\n",
        "\n",
        "    # Find and execute the function corresponding to the tool call\n",
        "    for call in tool_calls:\n",
        "        tool_name = call[\"name\"]\n",
        "        tool_args = call[\"args\"]\n",
        "        tool_call_id = call[\"id\"] # Get the tool call ID\n",
        "\n",
        "        # Simple lookup and execution (in a real app, use the ToolExecutor)\n",
        "        tool_to_run = next(\n",
        "            (t for t in ad_optimization_tools if t.name == tool_name), None\n",
        "        )\n",
        "\n",
        "        if tool_to_run:\n",
        "            try:\n",
        "                result = tool_to_run.invoke(tool_args)\n",
        "                # Format the tool result as a ToolMessage\n",
        "                tool_results.append({\n",
        "                    \"type\": \"tool_output\",\n",
        "                    \"tool_call_id\": tool_call_id, # Include the tool call ID\n",
        "                    \"content\": result\n",
        "                })\n",
        "            except Exception as e:\n",
        "                 # Handle tool execution errors and return an error message\n",
        "                 tool_results.append({\n",
        "                    \"type\": \"tool_output\",\n",
        "                    \"tool_call_id\": tool_call_id, # Include the tool call ID\n",
        "                    \"content\": f\"Error executing tool {tool_name}: {e}\"\n",
        "                })\n",
        "\n",
        "\n",
        "    # Add tool results to the state for the LLM to process next\n",
        "    # Need to format the tool results into a list of BaseMessage\n",
        "    tool_messages = [HumanMessage(content=str(r), name=\"tool_execution\") for r in tool_results]\n",
        "\n",
        "    return {\"messages\": tool_messages}\n",
        "\n",
        "def decide_next_step(state: AgentState) -> str:\n",
        "    \"\"\"Conditional edge: decides whether to continue analysis or finish.\"\"\"\n",
        "    print(f\"--- DECIDING NEXT STEP ---\")\n",
        "    print(f\"state['next_action']: {state.get('next_action')}\") # Use .get() for safety\n",
        "\n",
        "    next_action = state.get(\"next_action\")\n",
        "\n",
        "    if next_action == \"call_tool\":\n",
        "        print(\"Returning 'call_tool'\") # Corrected return value\n",
        "        return \"call_tool\"\n",
        "    elif next_action == \"FINISH\":\n",
        "        print(\"Returning 'end'\")\n",
        "        return \"end\"\n",
        "    else:\n",
        "        # After tool execution, go back to reasoning to summarize the result\n",
        "        print(\"Returning 'agent_reasoning'\")\n",
        "        return \"agent_reasoning\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S3eOtJKwukL1"
      },
      "outputs": [],
      "source": [
        "from langchain_core.messages import HumanMessage\n",
        "import pandas as pd, re\n",
        "\n",
        "def fetch_campaign_data(state: AgentState) -> dict:\n",
        "    print(\"--- FETCHING DATA ---\")\n",
        "    df = pd.read_excel(\"/content/marketing_campaign_dataset.xlsx\")\n",
        "    df.columns = [re.sub(r'[^a-z0-9]+', '_', c.strip().lower()) for c in df.columns]\n",
        "    df = df.head(50)\n",
        "\n",
        "    # map to your actual headers\n",
        "    campaign_col = \"campaign_id\"\n",
        "    adgroup_col  = \"campaign_type\"\n",
        "    clicks_col   = \"clicks\"          # used as a conversions proxy\n",
        "    impr_col     = \"impressions\"\n",
        "\n",
        "    simulated_data = {}\n",
        "    for camp, g in df.groupby(campaign_col):\n",
        "        entry = {\n",
        "            \"Impressions\": int(g[impr_col].sum()) if impr_col in g else None,\n",
        "            \"Clicks\": int(g[clicks_col].sum()) if clicks_col in g else None,\n",
        "            \"Conversions\": int(g[clicks_col].sum()) if clicks_col in g else None,\n",
        "            \"Target_CPA\": 50.00,\n",
        "            \"Ad_Groups\": {\n",
        "                str(ag): {\n",
        "                    \"Status\": \"Active\",\n",
        "                    \"CPA\": None,\n",
        "                    \"Bid\": None\n",
        "                }\n",
        "                for ag, _ in g.groupby(adgroup_col)\n",
        "            }\n",
        "        }\n",
        "        simulated_data[str(camp)] = entry\n",
        "\n",
        "    analysis_prompt = (\n",
        "        \"Ad Campaign Data for Optimization:\\n\"\n",
        "        f\"{simulated_data}\\n\\n\"\n",
        "        \"**Optimization Goal:** Reduce overall CPA to be closer to Target CPA ($50.00) \"\n",
        "        \"and maximize conversions. Recommend the *single best action* \"\n",
        "        \"using adjust_bid, pause_ad_group, or request_new_creatives.\"\n",
        "    )\n",
        "    new_messages = [HumanMessage(content=analysis_prompt)]\n",
        "    return {\"messages\": new_messages, \"campaign_data\": simulated_data}\n",
        "\n",
        "\n",
        "def agent_reasoning(state: AgentState) -> dict:\n",
        "    \"\"\"The LLM reasons and decides the next step (tool call or final answer).\"\"\"\n",
        "    print(\"--- AGENT REASONING ---\")\n",
        "\n",
        "    # Bind the tools to the LLM\n",
        "    llm_with_tools = llm.bind_tools(ad_optimization_tools)\n",
        "\n",
        "    # Define a system prompt to guide the LLM's role\n",
        "    system_prompt = (\n",
        "        \"You are an expert Ad Campaign Optimization Agent. \"\n",
        "        \"Your goal is to analyze the provided campaign data and decide the optimal next action. \"\n",
        "        \"You must use a tool if an optimization is possible. \"\n",
        "        \"If no tool is needed or you have executed a tool, provide a final, concise update.\"\n",
        "    )\n",
        "\n",
        "    prompt = ChatPromptTemplate.from_messages([\n",
        "        (\"system\", system_prompt),\n",
        "        (\"placeholder\", \"{messages}\")\n",
        "    ])\n",
        "\n",
        "    # Run the LLM to get a decision\n",
        "    chain = prompt | llm_with_tools\n",
        "    response = chain.invoke(state)\n",
        "\n",
        "    # Determine if a tool call was made\n",
        "    if response.tool_calls:\n",
        "        # If a tool is called, the next step is to execute it.\n",
        "        return {\"messages\": [response], \"next_action\": \"call_tool\"}\n",
        "    else:\n",
        "        # If no tool is called, the reasoning is the final response.\n",
        "        return {\"messages\": [response], \"next_action\": \"FINISH\"}\n",
        "\n",
        "\n",
        "def execute_tools(state: AgentState) -> dict:\n",
        "    \"\"\"Executes the tool call(s) decided by the agent_reasoning step.\"\"\"\n",
        "    print(\"--- EXECUTING TOOL ---\")\n",
        "\n",
        "    tool_calls = state[\"messages\"][-1].tool_calls\n",
        "    tool_results = []\n",
        "\n",
        "    # Find and execute the function corresponding to the tool call\n",
        "    for call in tool_calls:\n",
        "        tool_name = call[\"name\"]\n",
        "        tool_args = call[\"args\"]\n",
        "        tool_call_id = call[\"id\"] # Get the tool call ID\n",
        "\n",
        "        # Simple lookup and execution (in a real app, use the ToolExecutor)\n",
        "        tool_to_run = next(\n",
        "            (t for t in ad_optimization_tools if t.name == tool_name), None\n",
        "        )\n",
        "\n",
        "        if tool_to_run:\n",
        "            try:\n",
        "                result = tool_to_run.invoke(tool_args)\n",
        "                # Format the tool result as a ToolMessage\n",
        "                tool_results.append(ToolMessage(\n",
        "                    content=result,\n",
        "                    tool_call_id=tool_call_id # Include the tool call ID\n",
        "                ))\n",
        "            except Exception as e:\n",
        "                 # Handle tool execution errors and return an error message\n",
        "                 tool_results.append(ToolMessage(\n",
        "                    content=f\"Error executing tool {tool_name}: {e}\",\n",
        "                    tool_call_id=tool_call_id # Include the tool call ID\n",
        "                ))\n",
        "\n",
        "\n",
        "    # Add tool results to the state for the LLM to process next\n",
        "    return {\"messages\": tool_results}\n",
        "\n",
        "def decide_next_step(state: AgentState) -> str:\n",
        "    \"\"\"Conditional edge: decides whether to continue analysis or finish.\"\"\"\n",
        "    print(f\"--- DECIDING NEXT STEP ---\")\n",
        "    print(f\"state['next_action']: {state.get('next_action')}\") # Use .get() for safety\n",
        "\n",
        "    next_action = state.get(\"next_action\")\n",
        "\n",
        "    if next_action == \"call_tool\":\n",
        "        print(\"Returning 'call_tool'\") # Corrected return value\n",
        "        return \"call_tool\"\n",
        "    elif next_action == \"FINISH\":\n",
        "        print(\"Returning 'end'\")\n",
        "        return \"end\"\n",
        "    else:\n",
        "        # After tool execution, go back to reasoning to summarize the result\n",
        "        print(\"Returning 'agent_reasoning'\")\n",
        "        return \"agent_reasoning\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "155rDNATwf59",
        "outputId": "d3af045c-c11e-4495-e276-51b347f8c196"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--- STARTING AD OPTIMIZATION AGENT RUN ---\n",
            "--- FETCHING DATA ---\n",
            "--- AGENT REASONING ---\n",
            "--- DECIDING NEXT STEP ---\n",
            "state['next_action']: call_tool\n",
            "Returning 'call_tool'\n",
            "--- EXECUTING TOOL ---\n",
            "--- AGENT REASONING ---\n",
            "--- DECIDING NEXT STEP ---\n",
            "state['next_action']: FINISH\n",
            "Returning 'end'\n",
            "\n",
            "==================================================\n",
            "AGENT FINAL RECOMMENDATION & SUMMARY:\n",
            "I have paused the following underperforming ad groups: 2, 4, 6, 11, 15, 19, 41, and 49. Additionally, I have requested new creative assets for these campaigns to enhance performance. Awaiting design feedback on the new creatives.\n",
            "==================================================\n"
          ]
        }
      ],
      "source": [
        "# 5. Build the LangGraph Workflow\n",
        "workflow = StateGraph(AgentState)\n",
        "\n",
        "# Add nodes\n",
        "workflow.add_node(\"fetch_data\", fetch_campaign_data)\n",
        "workflow.add_node(\"agent_reasoning\", agent_reasoning)\n",
        "workflow.add_node(\"execute_tools\", execute_tools)\n",
        "\n",
        "# Set the start point\n",
        "workflow.set_entry_point(\"fetch_data\")\n",
        "\n",
        "# Add edges\n",
        "# From fetch_data, always go to reasoning\n",
        "workflow.add_edge(\"fetch_data\", \"agent_reasoning\")\n",
        "\n",
        "# Conditional edge from reasoning to decide if it's a tool call or the end\n",
        "workflow.add_conditional_edges(\n",
        "    \"agent_reasoning\",\n",
        "    decide_next_step,\n",
        "    {\"call_tool\": \"execute_tools\", \"end\": END}\n",
        ")\n",
        "\n",
        "# After executing a tool, cycle back to reasoning to formulate a final summary\n",
        "workflow.add_edge(\"execute_tools\", \"agent_reasoning\")\n",
        "\n",
        "# Compile the graph\n",
        "app = workflow.compile()\n",
        "\n",
        "# 6. Run the Agent\n",
        "print(\"--- STARTING AD OPTIMIZATION AGENT RUN ---\")\n",
        "\n",
        "# The agent runs autonomously until it hits the END node\n",
        "# It starts by fetching data, which primes the first message.\n",
        "final_state = app.invoke(\n",
        "    {\"messages\": [], \"campaign_data\": {}, \"next_action\": \"start\"},\n",
        "    config={\"recursion_limit\": 50}\n",
        ")\n",
        "\n",
        "# 7. Print Final Result\n",
        "final_message = final_state[\"messages\"][-1].content\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"AGENT FINAL RECOMMENDATION & SUMMARY:\")\n",
        "print(final_message)\n",
        "print(\"=\"*50)\n",
        "\n",
        "# Optional: Visualize the graph (requires pydot/graphviz)\n",
        "# from IPython.display import Image\n",
        "# Image(app.get_graph().draw_png())"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}